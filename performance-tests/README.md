# Pruebas de Rendimiento - E-commerce Microservices

Este directorio contiene pruebas de rendimiento completas para el sistema de microservicios de e-commerce usando Locust.

## üìã Pruebas Incluidas

### 1. üõçÔ∏è Prueba de Carga en Listado de Productos
**Archivo:** `product_listing_load_test.py`
- **Objetivo:** Evaluar el rendimiento del product-service v√≠a proxy-client
- **Endpoints:** `GET /api/products`, `GET /api/products/{id}`, `GET /api/categories/{id}`
- **Escenarios:** Listado de productos, consulta de detalles, navegaci√≥n por categor√≠as

### 2. üì¶ Prueba de Rendimiento en Creaci√≥n de √ìrdenes  
**Archivo:** `order_creation_load_test.py`
- **Objetivo:** Evaluar el rendimiento del order-service bajo picos de carga
- **Endpoints:** `POST /api/orders`, `GET /api/orders/{id}`, `GET /api/orders`
- **Escenarios:** Creaci√≥n de √≥rdenes, consulta de estado, listado de √≥rdenes

### 3. üë§ Prueba de Capacidad de Respuesta del User Service
**Archivo:** `user_service_load_test.py`  
- **Objetivo:** Evaluar el rendimiento del user-service en registros y consultas
- **Endpoints:** `POST /api/users`, `GET /api/users/{id}`, `PUT /api/users/{id}`
- **Escenarios:** Registro de usuarios, consulta de perfiles, actualizaci√≥n de datos

## üöÄ Configuraci√≥n y Ejecuci√≥n

### Prerrequisitos

1. **Python 3.7+** instalado
2. **Locust** instalado:
   ```bash
   pip install locust
   ```
3. **Sistema de microservicios ejecut√°ndose** en Docker Desktop
4. **API Gateway** accesible en `http://localhost:8080`

### Ejecuci√≥n R√°pida

```bash
# Navegar al directorio de pruebas
cd performance-tests

# Ejecutar suite completa con configuraci√≥n por defecto
python performance_test_suite.py --all

# Ejecutar prueba espec√≠fica
python performance_test_suite.py --test products
python performance_test_suite.py --test orders
python performance_test_suite.py --test users
```

### Configuraciones Predefinidas

```bash
# Prueba exploratoria (baja carga)
python performance_test_suite.py --all --users 5 --spawn-rate 1 --duration 60

# Prueba de carga normal 
python performance_test_suite.py --all --users 25 --spawn-rate 3 --duration 300

# Prueba de stress (alta carga)
python performance_test_suite.py --all --users 50 --spawn-rate 5 --duration 600

# Prueba de pico extremo
python performance_test_suite.py --all --users 100 --spawn-rate 10 --duration 300
```

### Ejecuci√≥n con Interfaz Web

```bash
# Iniciar Locust con interfaz web
locust -f product_listing_load_test.py --host=http://localhost:8080

# Abrir navegador en: http://localhost:8089
# Configurar usuarios y duraci√≥n desde la interfaz
```

## üìä M√©tricas y Reportes

### M√©tricas Clave Monitoreadas

- **Tiempo de Respuesta:** P50, P95, P99
- **Throughput:** Requests por segundo
- **Tasa de Errores:** Porcentaje de fallos
- **Concurrencia:** Usuarios simult√°neos
- **Latencia:** Tiempo de primera respuesta

### Archivos de Salida

```
performance_results/
‚îú‚îÄ‚îÄ {test}_report_{timestamp}.html     # Reporte HTML detallado
‚îú‚îÄ‚îÄ {test}_stats_{timestamp}.csv       # Estad√≠sticas CSV
‚îú‚îÄ‚îÄ {test}_results_{timestamp}.json    # Resultados JSON
‚îî‚îÄ‚îÄ summary_report_{timestamp}.json    # Reporte resumen
```

### Thresholds de Rendimiento

| Endpoint | Tiempo M√°ximo | Throughput M√≠nimo |
|----------|---------------|-------------------|
| `GET /api/products` | 2.0s | 50 RPS |
| `GET /api/products/{id}` | 1.0s | 100 RPS |
| `POST /api/orders` | 3.0s | 20 RPS |
| `POST /api/users` | 2.0s | 30 RPS |
| `GET /api/users/{id}` | 1.0s | 75 RPS |

## üîß Configuraci√≥n Avanzada

### Variables de Entorno

```bash
# Host del sistema bajo prueba
export PERF_TEST_HOST=http://localhost:8080

# Directorio de resultados
export PERF_RESULTS_DIR=./performance_results

# Nivel de logging
export PERF_LOG_LEVEL=INFO
```

### Configuraci√≥n Personalizada

Editar `performance_config.ini` para ajustar:
- Thresholds de rendimiento
- Configuraciones por servicio
- Par√°metros de monitoreo
- Formatos de reporte

## üèóÔ∏è Arquitectura de Pruebas

```
Cliente de Prueba (Locust)
    ‚Üì
API Gateway (puerto 8080)
    ‚Üì
Proxy Client (puerto 8700)
    ‚Üì
[Product Service | User Service | Order Service]
    ‚Üì
[Payment Service | Shipping Service] (seg√∫n el flujo)
```

## üìà Patrones de Carga Simulados

### Patr√≥n de Usuario Realista
1. **Navegaci√≥n de Productos** (50% del tiempo)
   - Listado de productos
   - Consulta de detalles
   - Navegaci√≥n por categor√≠as

2. **Creaci√≥n de √ìrdenes** (30% del tiempo)
   - Creaci√≥n de orden
   - Consulta de estado
   - Verificaci√≥n de detalles

3. **Gesti√≥n de Usuarios** (20% del tiempo)
   - Registro de usuarios
   - Consulta de perfil
   - Actualizaci√≥n de datos

### Patr√≥n de Carga de Stress
- Generaci√≥n r√°pida de usuarios
- Tiempo m√≠nimo entre requests
- Enfoque en endpoints cr√≠ticos
- Simulaci√≥n de picos de tr√°fico

## üêõ Troubleshooting

### Problemas Comunes

**Error: Connection refused**
```bash
# Verificar que el API Gateway est√© ejecut√°ndose
docker ps | grep api-gateway

# Verificar conectividad
curl http://localhost:8080/actuator/health
```

**Error: No tests were executed**
```bash
# Verificar que los archivos de prueba est√©n en el directorio correcto
ls -la *.py

# Ejecutar con modo verbose
locust -f product_listing_load_test.py --host=http://localhost:8080 -v
```

**Error: High failure rate**
```bash
# Revisar logs de los servicios
docker logs {container_name}

# Reducir la carga de prueba
python performance_test_suite.py --test products --users 5 --spawn-rate 1
```

### Logs y Debugging

```bash
# Ejecutar con logging detallado
python performance_test_suite.py --test products --users 10 --duration 60 --verbose

# Revisar archivos de resultados
cat performance_results/products_results_*.json | jq '.stderr'

# Monitorear recursos del sistema
htop
docker stats
```

## üìö Interpretaci√≥n de Resultados

### M√©tricas Cr√≠ticas

1. **Response Time P95 < 2s:** 95% de las requests responden en menos de 2 segundos
2. **Error Rate < 5%:** Menos del 5% de requests fallan
3. **Throughput > Threshold:** Supera el throughput m√≠nimo esperado
4. **Resource Usage < 80%:** CPU y memoria se mantienen bajo 80%

### Indicadores de Problemas

- ‚ö†Ô∏è **Tiempo de respuesta creciente:** Posible saturaci√≥n
- ‚ùå **Alta tasa de errores:** Problemas de configuraci√≥n o capacidad  
- üêå **Throughput decreciente:** Cuellos de botella en el sistema
- üí• **Fallos de conexi√≥n:** Problemas de red o servicios ca√≠dos

## üîÑ Integraci√≥n con CI/CD

### Jenkins Pipeline

```groovy
stage('Performance Tests') {
    steps {
        script {
            sh '''
                cd performance-tests
                python performance_test_suite.py --all --users 25 --duration 180
            '''
        }
    }
    post {
        always {
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'performance-tests/performance_results',
                reportFiles: '*.html',
                reportName: 'Performance Test Report'
            ])
        }
    }
}
```

### GitHub Actions

```yaml
- name: Run Performance Tests
  run: |
    cd performance-tests
    python performance_test_suite.py --all --users 20 --duration 120
    
- name: Upload Performance Reports
  uses: actions/upload-artifact@v3
  with:
    name: performance-reports
    path: performance-tests/performance_results/
```

## üìû Soporte

Para dudas o problemas con las pruebas de rendimiento:

1. Revisar la documentaci√≥n del sistema
2. Verificar logs de Docker containers  
3. Consultar archivos de configuraci√≥n
4. Revisar thresholds de rendimiento

---

**Autor:** Sistema de Pruebas E-commerce  
**Versi√≥n:** 1.0  
**√öltima actualizaci√≥n:** $(date)  
